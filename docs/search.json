[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Quarto Book",
    "section": "",
    "text": "主页 || 课程 || 视频 || 推文 || 资料",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Home</span>"
    ]
  },
  {
    "objectID": "body/A01_StataML.html",
    "href": "body/A01_StataML.html",
    "title": "2  欢迎访问 Stata ML 页面",
    "section": "",
    "text": "在本网站上，我们介绍了用于机器学习的 Stata 软件包。这些软件包包括旨在进行预测、模型选择和因果推断的功能。\n\n2.0.1 lassopack\nThe package lassopack implements lasso (Tibshirani 1996), square-root lasso (Belloni et al. 2011), elastic net (Zou & Hastie 2005), ridge regression (Hoerl & Kennard 1970), adaptive lasso (Zou 2006) and post-estimation OLS. lassopack also supports logistic lasso.\nlassopack 实现了以下算法：\n\nLasso（Tibshirani 1996）\n平方根 lasso（Belloni 等人 2011）\n弹性网（Zou & Hastie 2005）\n岭回归（Hoerl & Kennard 1970）\n自适应 lasso（Zou 2006）\n后估计 OLS\n\nlassopack 还支持逻辑回归 lasso。\n\n\n2.0.2 pdslasso\npdslasso 提供了有助于结构模型中因果推断的方法。该软件包允许从大量变量中选择控制变量和/或工具变量，适用于研究者希望估计一个或多个（可能是内生的）因果变量的因果影响的情境。\n\n\n2.0.3 pystacked\npystacked 实现了堆叠回归（Wolpert, 1992），通过 scikit-learn 的 sklearn.ensemble.StackingRegressor 和 sklearn.ensemble.StackingClassifier。堆叠方法将多个监督式机器学习模型（“基础学习器”）的预测结果结合起来，最终输出更优的预测结果。\n\n\n2.0.4 ddml\nddml 实现了双重/去偏机器学习（Double/Debiased Machine Learning, DDML）方法，支持五种不同的估计器，可灵活估计内生变量的因果效应，适用于具有未知函数形式和/或大量外生变量的情境。ddml 与 Stata 中许多现有的监督式机器学习程序兼容。",
    "crumbs": [
      "**StataDDML 主页简介**",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>欢迎访问 Stata ML 页面</span>"
    ]
  },
  {
    "objectID": "body/10_InstallStataPython.html",
    "href": "body/10_InstallStataPython.html",
    "title": "3  设置 Stata 的 Python 集成",
    "section": "",
    "text": "pystacked 至少需要 Stata 16（或更高版本）、Python 安装（3.8 或更高版本）以及 scikit-learn（0.24 或更高版本）。如果你想使用 ddml，也需要安装 Python。\nStataCorp 提供了详细的说明，介绍如何设置 Stata 的 Python 集成，分为三个博客条目：链接1、链接2、链接3。\n以下是我们简要概述的步骤：\n\n3.0.0.1 1. Python 安装\n你有（至少）三种选择：\n\n对许多人来说，最简单的方式是安装 Anaconda，可以从这里下载。Anaconda 是一个 Python 发行版，带有最重要的包、包管理器和编辑器。\n另外，你也可以从这里下载并安装普通的 Python。\n如果你已经在系统中安装了一个较新的 Python 版本，可以为 Stata 设置一个单独的 Python 环境。这是可选的，但如果你希望在不同的项目中使用不同的库，这可能会很有用（参见此处的说明）。\n\n\n\n3.0.0.2 2. 设置 Python 集成\n安装 Python 后，你需要告诉 Stata 如何找到 Python 安装位置。\n你可以使用以下命令在系统中搜索 Python 安装：\n. python search\n注意，可能会显示多个 Python 安装（例如，MacOS 自带了一个旧版本的 Python），Stata 可能无法找到系统中的所有 Python 安装。\n要将 Stata 与特定的 Python 安装链接，使用：\npython set exec &lt;pyexecutable&gt;, permanently\n其中 &lt;pyexecutable&gt; 可能是例如：/usr/local/bin/python3、C:\\Program Files\\Python38\\python.exe 或 C:\\Users\\&lt;user&gt;\\AppData\\Local\\Programs\\Python\\Python38\\python.exe，具体取决于你的操作系统以及 Python 的安装位置。\n输入 python query 来检查安装是否正确链接：\n. python query\n------------------------------------------------------------------\n    Python 设置\n      set python_exec      /usr/bin/python3\n      set python_userpath  \n\n    Python 系统信息\n      初始化状态          no\n      版本号              3.8.9\n      架构                64位\n你可以通过输入 python 启动 Python 环境，输入 end 返回 Stata 环境：\n. python\n----------------------------------------------- python (type end to exit) ----------\n&gt;&gt;&gt; print('hello')\nhello\n&gt;&gt;&gt; end\n------------------------------------------------------------------------------------\n\n\n3.0.0.3 3. 管理包\npystacked 需要 scikit-learn（简称 sklearn）。你可以在 Stata 中检查 sklearn 是否已安装：\n. python which sklearn\n&lt;module 'sklearn' from '/Users/&lt;username&gt;/Library/Python/3.8/lib/python/site-packages/sklearn/__init__.py'&gt;\n如果 Stata 找不到 sklearn，可能是因为你将 Stata 链接到了错误的 Python 安装，或者你还需要安装 sklearn。\n如果你使用 Anaconda，sklearn 会自动包含，你可以通过 Anaconda 的 Python 发行版更新 scikit-learn（参见此处）或在终端中使用 conda install。\n如果不使用 Anaconda，可以通过 pip 安装和更新包。例如，你可以在终端或 Stata 中直接输入以下命令安装 sklearn：\n. shell &lt;Python path&gt; -m pip install -U scikit-learn\n其中 &lt;Python path&gt; 是你希望与 Stata 一起使用的 Python 安装路径。如果你只想使用默认的 Python 安装，也可以将 &lt;Python path&gt; 替换为 python3（Mac 上）或 py（Windows 上）。\n\n\n3.0.0.4 4. 检查是否正常工作\n为了测试 Stata 的 Python 集成是否在系统上正常工作，请在 Stata 中运行以下测试代码：\nclear all\nuse http://www.stata-press.com/data/r16/iris\n\npython:\nfrom sfi import Data\nimport numpy as np\nfrom sklearn.svm import SVC\n\n# 使用 sfi Data 类将 Stata 变量中的数据拉取到 Python 中\nX = np.array(Data.get(\"seplen sepwid petlen petwid\"))\ny = np.array(Data.get(\"iris\"))\n\n# 使用数据训练 C-Support Vector Classifier\nsvc_clf = SVC(gamma='auto')\nsvc_clf.fit(X, y)\nend\n为了测试 pystacked 是否正常工作，可以在 Stata 中运行以下测试代码：\nclear all\nuse https://statalasso.github.io/dta/cal_housing.dta, clear\nset seed 42\ngen train=runiform()\nreplace train=train&lt;.75\nset seed 42\npystacked medh longi-medi if train\n\n\n3.0.0.5 可选：使用 Stata 和 Python 环境\n你也可以将 Stata 与 Python 环境结合使用。如果你希望在系统中使用多个版本的 Python，这可能会很有用。如何使用 Python 环境的完整指南可见此处。以下是详细的步骤：\n\n3.0.0.5.1 MacOS:\n\n关闭 Stata 并创建一个文件夹用于保存 Python 环境。我使用的文件夹是 /Users/myname/python_envs。\n打开终端并导航到该文件夹。在我的示例中，这将是 cd /Users/myname/python_envs。\n设置 Python 环境：python3 -m venv myenv，其中 myenv 可以替换为你想要使用的任何名称。\n激活环境：source venv/bin/activate\n安装 sklearn：python3 -m pip install scikit-learn\n退出环境：deactivate\n打开 Stata 并输入：python set exec \"/Users/myname/python_envs/myenv/bin/python3\", perm\n\n\n\n3.0.0.5.2 Windows:\n\n关闭 Stata 并创建一个文件夹用于保存 Python 环境。我使用的文件夹是 C:\\Users\\myname\\python_envs。\n打开命令提示符并导航到该文件夹。在我的示例中，这将是 cd C:\\Users\\myname\\python_envs。\n设置 Python 环境：py -m venv myenv，其中 myenv 可以替换为你想要使用的任何名称。\n激活环境：.\\venv\\bin\\activate\n安装 sklearn：py -m pip install scikit-learn\n退出环境：deactivate\n打开 Stata 并输入：python set exec \"C:\\Users\\myname\\python_envs\\Scripts\\python.exe\", perm",
    "crumbs": [
      "**Stata-Python设置**",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>设置 Stata 的 Python 集成</span>"
    ]
  },
  {
    "objectID": "body/01_intro.html",
    "href": "body/01_intro.html",
    "title": "4  设置 Stata 的 Python 集成",
    "section": "",
    "text": "pystacked 至少需要 Stata 16（或更高版本）、Python 安装（3.8 或更高版本）以及 scikit-learn（0.24 或更高版本）。如果你想使用 ddml，也需要安装 Python。\nStataCorp 提供了详细的说明，介绍如何设置 Stata 的 Python 集成，分为三个博客条目：链接1、链接2、链接3。\n以下是我们简要概述的步骤：\n\n4.0.0.1 1. Python 安装\n你有（至少）三种选择：\n\n对许多人来说，最简单的方式是安装 Anaconda，可以从这里下载。Anaconda 是一个 Python 发行版，带有最重要的包、包管理器和编辑器。\n另外，你也可以从这里下载并安装普通的 Python。\n如果你已经在系统中安装了一个较新的 Python 版本，可以为 Stata 设置一个单独的 Python 环境。这是可选的，但如果你希望在不同的项目中使用不同的库，这可能会很有用（参见此处的说明）。\n\n\n\n4.0.0.2 2. 设置 Python 集成\n安装 Python 后，你需要告诉 Stata 如何找到 Python 安装位置。\n你可以使用以下命令在系统中搜索 Python 安装：\n. python search\n注意，可能会显示多个 Python 安装（例如，MacOS 自带了一个旧版本的 Python），Stata 可能无法找到系统中的所有 Python 安装。\n要将 Stata 与特定的 Python 安装链接，使用：\npython set exec &lt;pyexecutable&gt;, permanently\n其中 &lt;pyexecutable&gt; 可能是例如：/usr/local/bin/python3、C:\\Program Files\\Python38\\python.exe 或 C:\\Users\\&lt;user&gt;\\AppData\\Local\\Programs\\Python\\Python38\\python.exe，具体取决于你的操作系统以及 Python 的安装位置。\n输入 python query 来检查安装是否正确链接：\n.  python query\n------------------------------------------------------------------ \n    Python Settings\n      set python_exec      /usr/bin/python3\n      set python_userpath  \n\n    Python system information\n      initialized          no\n      version              3.8.9\n      architecture         64-bit\n你可以通过输入 python 启动 Python 环境，输入 end 返回 Stata 环境：\n. python\n----------------------------------------------- python (type end to exit) ----------\n&gt;&gt;&gt; print('hello')\nhello\n&gt;&gt;&gt; end\n------------------------------------------------------------------------------------\n\n\n4.0.0.3 3. 管理包\npystacked 需要 scikit-learn（简称 sklearn）。你可以在 Stata 中检查 sklearn 是否已安装：\n. python which sklearn\n&lt;module 'sklearn' from '/Users/&lt;username&gt;/Library/Python/3.8/lib/python/site-packages/sklearn/__init__.py'&gt;\n如果 Stata 找不到 sklearn，可能是因为你将 Stata 链接到了错误的 Python 安装，或者你还需要安装 sklearn。\n如果你使用 Anaconda，sklearn 会自动包含，你可以通过 Anaconda 的 Python 发行版更新 scikit-learn（参见此处）或在终端中使用 conda install。\n如果不使用 Anaconda，可以通过 pip 安装和更新包。例如，你可以在终端或 Stata 中直接输入以下命令安装 sklearn：\n. shell &lt;Python path&gt; -m pip install -U scikit-learn\n其中 &lt;Python path&gt; 是你希望与 Stata 一起使用的 Python 安装路径。如果你只想使用默认的 Python 安装，也可以将 &lt;Python path&gt; 替换为 python3（Mac 上）或 py（Windows 上）。\n\n\n4.0.0.4 4. 检查是否正常工作\n为了测试 Stata 的 Python 集成是否在系统上正常工作，请在 Stata 中运行以下测试代码：\nclear all\nuse http://www.stata-press.com/data/r16/iris\n\npython:\nfrom sfi import Data\nimport numpy as np\nfrom sklearn.svm import SVC\n\n# 使用 sfi Data 类将 Stata 变量中的数据拉取到 Python 中\nX = np.array(Data.get(\"seplen sepwid petlen petwid\"))\ny = np.array(Data.get(\"iris\"))\n\n# 使用数据训练 C-Support Vector Classifier\nsvc_clf = SVC(gamma='auto')\nsvc_clf.fit(X, y)\nend\n\n\n\nclear all \nuse http://www.stata-press.com/data/r16/iris\n\npython:\nfrom sfi import Data\nimport numpy as np\nfrom sklearn.svm import SVC\n\n# Use the sfi Data class to pull data from Stata variables into Python\nX = np.array(Data.get(\"seplen sepwid petlen petwid\"))\ny = np.array(Data.get(\"iris\"))\n\n# Use the data to train C-Support Vector Classifier\nsvc_clf = SVC(gamma='auto')\nsvc_clf.fit(X, y)\nend\n为了测试 pystacked 是否正常工作，可以在 Stata 中运行以下测试代码：\nclear all\nuse https://statalasso.github.io/dta/cal_housing.dta, clear\nset seed 42\ngen train=runiform()\nreplace train=train&lt;.75\nset seed 42\npystacked medh longi-medi if train\n\n\n4.0.0.5 可选：使用 Stata 和 Python 环境\n你也可以将 Stata 与 Python 环境结合使用。如果你希望在系统中使用多个版本的 Python，这可能会很有用。如何使用 Python 环境的完整指南可见此处。以下是详细的步骤：\n\n4.0.0.5.1 MacOS:\n\n关闭 Stata 并创建一个文件夹用于保存 Python 环境。我使用的文件夹是 /Users/myname/python_envs。\n打开终端并导航到该文件夹。在我的示例中，这将是 cd /Users/myname/python_envs。\n设置 Python 环境：python3 -m venv myenv，其中 myenv 可以替换为你想要使用的任何名称。\n激活环境：source venv/bin/activate\n安装 sklearn：python3 -m pip install scikit-learn\n退出环境：deactivate\n打开 Stata 并输入：python set exec \"/Users/myname/python_envs/myenv/bin/python3\", perm\n\n\n\n4.0.0.5.2 Windows:\n\n关闭 Stata 并创建一个文件夹用于保存 Python 环境。我使用的文件夹是 C:\\Users\\myname\\python_envs。\n打开命令提示符并导航到该文件夹。在我的示例中，这将是 cd C:\\Users\\myname\\python_envs。\n设置 Python 环境：py -m venv myenv，其中 myenv 可以替换为你想要使用的任何名称。\n激活环境：.\\venv\\bin\\activate\n安装 sklearn：py -m pip install scikit-learn\n退出环境：deactivate\n打开 Stata 并输入：python set exec \"C:\\Users\\myname\\python_envs\\Scripts\\python.exe\", perm",
    "crumbs": [
      "**DDML模型**",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>设置 Stata 的 Python 集成</span>"
    ]
  },
  {
    "objectID": "body/02_data.html",
    "href": "body/02_data.html",
    "title": "5  设置 Stata 的 Python 集成",
    "section": "",
    "text": "pystacked 至少需要 Stata 16（或更高版本）、Python 安装（3.8 或更高版本）以及 scikit-learn（0.24 或更高版本）。如果你想使用 ddml，也需要安装 Python。\nStataCorp 提供了详细的说明，介绍如何设置 Stata 的 Python 集成，分为三个博客条目：链接1、链接2、链接3。\n以下是我们简要概述的步骤：\n\n5.0.0.1 1. Python 安装\n你有（至少）三种选择：\n\n对许多人来说，最简单的方式是安装 Anaconda，可以从这里下载。Anaconda 是一个 Python 发行版，带有最重要的包、包管理器和编辑器。\n另外，你也可以从这里下载并安装普通的 Python。\n如果你已经在系统中安装了一个较新的 Python 版本，可以为 Stata 设置一个单独的 Python 环境。这是可选的，但如果你希望在不同的项目中使用不同的库，这可能会很有用（参见此处的说明）。\n\n\n\n5.0.0.2 2. 设置 Python 集成\n安装 Python 后，你需要告诉 Stata 如何找到 Python 安装位置。\n你可以使用以下命令在系统中搜索 Python 安装：\n. python search\n注意，可能会显示多个 Python 安装（例如，MacOS 自带了一个旧版本的 Python），Stata 可能无法找到系统中的所有 Python 安装。\n要将 Stata 与特定的 Python 安装链接，使用：\npython set exec &lt;pyexecutable&gt;, permanently\n其中 &lt;pyexecutable&gt; 可能是例如：/usr/local/bin/python3、C:\\Program Files\\Python38\\python.exe 或 C:\\Users\\&lt;user&gt;\\AppData\\Local\\Programs\\Python\\Python38\\python.exe，具体取决于你的操作系统以及 Python 的安装位置。\n输入 python query 来检查安装是否正确链接：\n.  python query\n------------------------------------------------------------------ \n    Python Settings\n      set python_exec      /usr/bin/python3\n      set python_userpath  \n\n    Python system information\n      initialized          no\n      version              3.8.9\n      architecture         64-bit\n你可以通过输入 python 启动 Python 环境，输入 end 返回 Stata 环境：\n. python\n----------------------------------------------- python (type end to exit) ----------\n&gt;&gt;&gt; print('hello')\nhello\n&gt;&gt;&gt; end\n------------------------------------------------------------------------------------\n\n\n5.0.0.3 3. 管理包\npystacked 需要 scikit-learn（简称 sklearn）。你可以在 Stata 中检查 sklearn 是否已安装：\n. python which sklearn\n&lt;module 'sklearn' from '/Users/&lt;username&gt;/Library/Python/3.8/lib/python/site-packages/sklearn/__init__.py'&gt;\n如果 Stata 找不到 sklearn，可能是因为你将 Stata 链接到了错误的 Python 安装，或者你还需要安装 sklearn。\n如果你使用 Anaconda，sklearn 会自动包含，你可以通过 Anaconda 的 Python 发行版更新 scikit-learn（参见此处）或在终端中使用 conda install。\n如果不使用 Anaconda，可以通过 pip 安装和更新包。例如，你可以在终端或 Stata 中直接输入以下命令安装 sklearn：\n. shell &lt;Python path&gt; -m pip install -U scikit-learn\n其中 &lt;Python path&gt; 是你希望与 Stata 一起使用的 Python 安装路径。如果你只想使用默认的 Python 安装，也可以将 &lt;Python path&gt; 替换为 python3（Mac 上）或 py（Windows 上）。\n\n\n5.0.0.4 4. 检查是否正常工作\n为了测试 Stata 的 Python 集成是否在系统上正常工作，请在 Stata 中运行以下测试代码：\nclear all\nuse http://www.stata-press.com/data/r16/iris\n\npython:\nfrom sfi import Data\nimport numpy as np\nfrom sklearn.svm import SVC\n\n# 使用 sfi Data 类将 Stata 变量中的数据拉取到 Python 中\nX = np.array(Data.get(\"seplen sepwid petlen petwid\"))\ny = np.array(Data.get(\"iris\"))\n\n# 使用数据训练 C-Support Vector Classifier\nsvc_clf = SVC(gamma='auto')\nsvc_clf.fit(X, y)\nend\n\n\n\nclear all \nuse http://www.stata-press.com/data/r16/iris\n\npython:\nfrom sfi import Data\nimport numpy as np\nfrom sklearn.svm import SVC\n\n# Use the sfi Data class to pull data from Stata variables into Python\nX = np.array(Data.get(\"seplen sepwid petlen petwid\"))\ny = np.array(Data.get(\"iris\"))\n\n# Use the data to train C-Support Vector Classifier\nsvc_clf = SVC(gamma='auto')\nsvc_clf.fit(X, y)\nend\n为了测试 pystacked 是否正常工作，可以在 Stata 中运行以下测试代码：\nclear all\nuse https://statalasso.github.io/dta/cal_housing.dta, clear\nset seed 42\ngen train=runiform()\nreplace train=train&lt;.75\nset seed 42\npystacked medh longi-medi if train\n\n\n5.0.0.5 可选：使用 Stata 和 Python 环境\n你也可以将 Stata 与 Python 环境结合使用。如果你希望在系统中使用多个版本的 Python，这可能会很有用。如何使用 Python 环境的完整指南可见此处。以下是详细的步骤：\n\n5.0.0.5.1 MacOS:\n\n关闭 Stata 并创建一个文件夹用于保存 Python 环境。我使用的文件夹是 /Users/myname/python_envs。\n打开终端并导航到该文件夹。在我的示例中，这将是 cd /Users/myname/python_envs。\n设置 Python 环境：python3 -m venv myenv，其中 myenv 可以替换为你想要使用的任何名称。\n激活环境：source venv/bin/activate\n安装 sklearn：python3 -m pip install scikit-learn\n退出环境：deactivate\n打开 Stata 并输入：python set exec \"/Users/myname/python_envs/myenv/bin/python3\", perm\n\n\n\n5.0.0.5.2 Windows:\n\n关闭 Stata 并创建一个文件夹用于保存 Python 环境。我使用的文件夹是 C:\\Users\\myname\\python_envs。\n打开命令提示符并导航到该文件夹。在我的示例中，这将是 cd C:\\Users\\myname\\python_envs。\n设置 Python 环境：py -m venv myenv，其中 myenv 可以替换为你想要使用的任何名称。\n激活环境：.\\venv\\bin\\activate\n安装 sklearn：py -m pip install scikit-learn\n退出环境：deactivate\n打开 Stata 并输入：python set exec \"C:\\Users\\myname\\python_envs\\Scripts\\python.exe\", perm",
    "crumbs": [
      "**DDML模型**",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>设置 Stata 的 Python 集成</span>"
    ]
  },
  {
    "objectID": "body/03_PartialLinearIVModel.html",
    "href": "body/03_PartialLinearIVModel.html",
    "title": "6  部分线性工具变量（IV）模型",
    "section": "",
    "text": "6.0.0.1 准备工作\n我们加载数据、定义全局宏并设置种子。\n. use https://statalasso.github.io/dta/AJR.dta, clear\n. global Y logpgp95\n. global D avexpr\n. global Z logem4\n. global X lat_abst edes1975 avelf temp* humid* steplow-oilres\n. set seed 42\n\n\n6.0.0.2 步骤 1: 初始化\n由于数据集非常小，我们考虑使用 30 个交叉拟合折叠。\n. ddml init iv, kfolds(30)\n\n\n6.0.0.3 步骤 2: 添加学习器\n部分线性 IV 模型有三个条件期望：\n\n\\(E[Y \\mid X]\\)\n\\(E[D \\mid X]\\)\n\\(E[Z \\mid X]\\)\n\n对于每个简化方程，我们添加两个学习器：regress 和 rforest。\n由于 rforest 的 predict 命令不支持变量类型，因此需要为 rforest 添加选项 vtype(none)。\n. ddml E[Y|X]: reg $Y $X\nLearner Y1_reg added successfully.\n. ddml E[Y|X], vtype(none): rforest $Y $X, type(reg)\nLearner Y2_rforest added successfully.\n. ddml E[D|X]: reg $D $X\nLearner D1_reg added successfully.\n. ddml E[D|X], vtype(none): rforest $D $X, type(reg)\nLearner D2_rforest added successfully.\n. ddml E[Z|X]: reg $Z $X\nLearner Z1_reg added successfully.\n. ddml E[Z|X], vtype(none): rforest $Z $X, type(reg)\nLearner Z2_rforest added successfully.\n\n\n6.0.0.4 步骤 3/4: 交叉拟合与估计\n我们使用 shortstack 选项来组合基础学习器。简短堆叠是比堆叠更节省计算资源的替代方法。堆叠依赖于交叉验证的预测值来获得基础学习器的相对权重，而简短堆叠则使用交叉拟合的预测值。\n. qui ddml crossfit\n. ddml estimate, robust\nDDML 估计结果：\nspec  r     Y learner     D learner         b        SE     Z learner\n opt  1    Y2_rforest    D2_rforest     0.772  ( 0.207)              \n  ss  1  [shortstack]          [ss]     0.716  ( 0.196)          [ss]\nopt = minimum MSE specification for that resample.\n\nShortstack DDML model\ny-E[y|X]  = logpgp95_ss_1                          Number of obs   =        64\nD-E[D|X,Z]= avexpr_ss_1\nZ-E[Z|X]  = logem4_ss_1\n------------------------------------------------------------------------------\n             |               Robust\n    logpgp95 | Coefficient  std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n      avexpr |   .7158468   .1958356     3.66   0.000     .3320162    1.099677\n       _cons |  -.0308525   .0914993    -0.34   0.736    -.2101878    .1484828\n------------------------------------------------------------------------------\n\n\n6.0.0.5 手动估计\n如果您想知道 ddml 在后台执行了什么，可以使用以下命令：\n. ddml estimate, allcombos spec(8) rep(1) robust\nDDML 估计结果：\nspec  r     Y learner     D learner         b        SE     Z learner\n   1  1        Y1_reg        D1_reg     0.378  ( 0.125)        Z1_reg\n   2  1        Y1_reg        D1_reg    -0.187  ( 1.573)    Z2_rforest\n   3  1        Y1_reg    D2_rforest     2.413  ( 3.594)        Z1_reg\n   4  1        Y1_reg    D2_rforest     0.083  ( 0.475)    Z2_rforest\n   5  1    Y2_rforest        D1_reg     0.123  ( 0.207)        Z1_reg\n   6  1    Y2_rforest        D1_reg    -1.749  ( 4.690)    Z2_rforest\n   7  1    Y2_rforest    D2_rforest     0.783  ( 0.504)        Z1_reg\n*  8  1    Y2_rforest    D2_rforest     0.772  ( 0.207)    Z2_rforest\n  ss  1  [shortstack]          [ss]     0.716  ( 0.196)          [ss]\n* = minimum MSE specification for that resample.\n\nMin MSE DDML model, specification 8\ny-E[y|X]  = Y2_rforest_1                           Number of obs   =        64\nD-E[D|X,Z]= D2_rforest_1\nZ-E[Z|X]  = Z2_rforest_1\n------------------------------------------------------------------------------\n             |               Robust\n    logpgp95 | Coefficient  std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n      avexpr |    .772314   .2068282     3.73   0.000     .3669382     1.17769\n       _cons |  -.0119092   .1009289    -0.12   0.906    -.2097263    .1859079\n------------------------------------------------------------------------------\n\n\n6.0.0.6 工具变量回归\n. ivreg Y2_rf (D2_rf = Z2_rf), robust\n工具变量 2SLS 回归\nInstrumental variables 2SLS regression          Number of obs     =         64\n                                                F(1, 62)          =      13.94\n                                                Prob &gt; F          =     0.0004\n                                                R-squared         =          .\n                                                Root MSE          =     .80209\n\n------------------------------------------------------------------------------\n             |               Robust\nY2_rforest_1 | Coefficient  std. err.      t    P&gt;|t|     [95% conf. interval]\n-------------+----------------------------------------------------------------\nD2_rforest_1 |    .772314   .2068282     3.73   0.000     .3588703    1.185758\n       _cons |  -.0119092   .1009289    -0.12   0.906    -.2136633    .1898448\n------------------------------------------------------------------------------\nInstrumented: D2_rforest_1\n Instruments: Z2_rforest_1",
    "crumbs": [
      "**DDML模型**",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>部分线性工具变量（IV）模型</span>"
    ]
  },
  {
    "objectID": "body/04_PartiallylinearmodelwithStacking.html",
    "href": "body/04_PartiallylinearmodelwithStacking.html",
    "title": "7  部分线性模型与堆叠回归",
    "section": "",
    "text": "堆叠回归是一种简单且强大的方法，用于结合多个学习器的预测结果。在 Stata 中可以通过 pystacked 包实现（见此处）。以下是使用部分线性模型的示例，但它也可以与任何由 ddml 支持的模型一起使用。\n\n7.0.0.1 步骤 1: 初始化\n准备：使用上述数据和全局变量。为这个新的估计使用名称 m1，以区别于使用默认名称 m0 的前一个示例。这样可以为比较提供多个估计。此外，还指定了 5 次交叉拟合重复。\n. set seed 42\n. ddml init partial, kfolds(2) reps(5) mname(m1)\n交叉拟合重复次数 DDML 的结果取决于精确的交叉拟合折数分割。我们建议在不同的随机折数上多次重新运行（最终）模型；请参见选项 reps(integer)。\n\n\n7.0.0.2 步骤 2: 添加学习器\n为估计条件期望添加监督学习器。堆叠集成中的第一个学习器是 OLS。我们还使用交叉验证的 Lasso、Ridge 和两种不同设置的随机森林，并将它们保存在以下宏中：\n. global rflow max_features(5) min_samples_leaf(1) max_samples(.7)\n. global rfhigh max_features(5) min_samples_leaf(10) max_samples(.7)\n在每一步中，我们添加了 mname(m1) 选项，以确保学习器不会被添加到仍在内存中的 m0 模型中。我们还使用 learner(varname) 选项指定包含估计条件期望的变量名，以避免覆盖使用默认命名为 m0 模型创建的变量。\n. ddml E[Y|X], mname(m1) learner(Y_m1): pystacked $Y $X            || /// \n&gt;                                method(ols)                       || /// \n&gt;                                method(lassocv)                   || /// \n&gt;                                method(ridgecv)                   || /// \n&gt;                                method(rf) opt($rflow)            || /// \n&gt;                                method(rf) opt($rfhigh), type(reg)\nLearner Y_m1 added successfully.\n. ddml E[D|X], mname(m1) learner(D_m1): pystacked $D $X            || /// \n&gt;                                method(ols)                       || /// \n&gt;                                method(lassocv)                   || /// \n&gt;                                method(ridgecv)                   || /// \n&gt;                                method(rf) opt($rflow)            || /// \n&gt;                                method(rf) opt($rfhigh), type(reg)\nLearner D_m1 added successfully.\n\n\n7.0.0.3 选项说明\n注意：“：”前和第一个逗号后的选项指的是 ddml，最后逗号后的选项指的是估计命令。确保不要混淆这两类选项。\n检查学习器是否已正确添加（省略输出）：\n. ddml desc, mname(m1) learners\n\n\n7.0.0.4 步骤 3/4: 交叉拟合和估计\n. qui ddml crossfit, mname(m1)\n. ddml estimate, mname(m1) robust\nDDML 估计结果：\nspec  r     Y learner     D learner         b        SE\n opt  1          Y_m1          D_m1  7362.283 (937.426)\n opt  2          Y_m1          D_m1  6958.283 (899.946)\n opt  3          Y_m1          D_m1  6531.201 (872.895)\n opt  4          Y_m1          D_m1  6532.662 (952.414)\n opt  5          Y_m1          D_m1  6672.368 (981.239)\nopt = minimum MSE specification for that resample.\n\nMean/med.   Y learner     D learner         b        SE\n mse mn     [min-mse]         [mse]  6811.360 (973.863)\n mse md     [min-mse]         [mse]  6672.368 (962.606)\n\nMedian over min-mse specifications\ny-E[y|X]  = Y_m1                                   Number of obs   =      9915\nD-E[D|X,Z]= D_m1\n------------------------------------------------------------------------------\n             |               Robust\n     net_tfa | Coefficient  std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n        e401 |   6672.368   962.6062     6.93   0.000     4785.695    8559.042\n------------------------------------------------------------------------------\n5 次重新抽样的总结：\n       D eqn      mean       min       p25       p50       p75       max\n        e401   6811.3596 6531.2007 6532.6626 6672.3682 6958.2832 7362.2832\n检查 pystacked 使用的学习器权重（未显示）：\n. ddml extract, mname(m1) show(pystacked)",
    "crumbs": [
      "**DDML模型**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>部分线性模型与堆叠回归</span>"
    ]
  },
  {
    "objectID": "body/05_Interactive.html",
    "href": "body/05_Interactive.html",
    "title": "8  交互式模型",
    "section": "",
    "text": "8.0.0.1 准备\n我们加载数据、定义全局宏并设置种子。\n. webuse cattaneo2, clear\n(Excerpt from Cattaneo (2010) Journal of Econometrics 155: 138–154)\n. global Y bweight\n. global D mbsmoke\n. global X mage prenatal1 mmarried fbaby mage medu\n. set seed 42\n\n\n8.0.0.2 步骤 1: 初始化\n我们使用 5 个折叠和 5 次重采样；也就是说，我们使用随机选择的折叠估计模型 5 次。\n. ddml init interactive, kfolds(5) reps(5)\n\n\n8.0.0.3 步骤 2: 添加学习器\n我们需要估计以下条件期望：\n\n\\(E[Y \\mid X, D = 0]\\)\n\\(E[Y \\mid X, D = 1]\\)\n\\(E[D \\mid X]\\)\n\n前两个条件期望一起添加。\n我们考虑了两个监督学习器：线性回归和梯度提升树（在 pystacked 中实现）。注意，对于 \\(E[Y \\mid X, D]\\) 使用梯度提升回归树，而对于 \\(E[D \\mid X]\\) 使用梯度提升分类树。\n. ddml E[Y|X,D]: reg $Y $X\nLearner Y1_reg added successfully.\n. ddml E[Y|X,D]: pystacked $Y $X, type(reg) method(gradboost)\nLearner Y2_pystacked added successfully.\n. ddml E[D|X]: logit $D $X\nLearner D1_logit added successfully.\n. ddml E[D|X]: pystacked $D $X, type(class) method(gradboost)\nLearner D2_pystacked added successfully.\n\n\n8.0.0.4 步骤 3: 交叉拟合\n. ddml crossfit\n\n\n8.0.0.5 步骤 4: 估计\n在最终估计步骤中，我们可以估计平均处理效应（默认）或处理组的平均处理效应（atet；输出未显示）。\n. ddml estimate\nDDML 估计结果（ATE）：\nspec  r    Y0 learner    Y1 learner     D learner         b        SE\n opt  1  Y1_pystacked  Y1_pystacked  D1_pystacked  -219.583  (26.027)\n opt  2  Y1_pystacked  Y1_pystacked  D1_pystacked  -220.967  (25.586)\n opt  3  Y1_pystacked  Y1_pystacked  D1_pystacked  -227.103  (26.256)\n opt  4  Y1_pystacked  Y1_pystacked  D1_pystacked  -221.207  (25.830)\n opt  5  Y1_pystacked  Y1_pystacked  D1_pystacked  -224.497  (25.840)\nopt = minimum MSE specification for that resample.\n\nMean/med.  Y0 learner    Y1 learner     D learner         b        SE\n mse mn     [min-mse]         [mse]         [mse]  -222.672  (26.045)\n mse md     [min-mse]         [mse]         [mse]  -221.207  (26.049)\n\nMedian over 5 min-mse specifications (ATE)\nE[y|X,D=0]   = Y1_pystacked                        Number of obs   =      4642\nE[y|X,D=1]   = Y1_pystacked\nE[D|X]       = D1_pystacked\n------------------------------------------------------------------------------\n             |               Robust\n     bweight | Coefficient  std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n     mbsmoke |  -221.2069    26.0486    -8.49   0.000    -272.2612   -170.1526\n------------------------------------------------------------------------------\n5 次重新抽样的总结：\n       D eqn      mean       min       p25       p50       p75       max\n     mbsmoke   -222.6716 -227.1032 -224.4971 -221.2069 -220.9675 -219.5831\n\n\n8.0.0.6 继续估计 ATET：\n. qui ddml estimate, atet\n请注意，我们已指定 5 次重采样迭代（reps(5)）。默认情况下，显示每次重采样迭代的最小 MSE 规格的中位数。底部显示了重采样迭代的摘要统计表。\n\n\n\n8.0.1 简短堆叠\n如果我们想使用相同的两个基础学习器，但采用简短堆叠而不是堆叠方法，可以将学习器单独输入，并使用 shortstack 选项：\n. set seed 42\n. ddml init interactive, kfolds(5) reps(5)\n. ddml E[Y|X,D]: reg $Y $X\n. ddml E[Y|X,D]: pystacked $Y $X, type(reg) method(gradboost)\n. ddml E[D|X]: logit $D $X\n. ddml E[D|X]: pystacked $D $X, type(class) method(gradboost)\n. ddml crossfit, shortstack\n. ddml estimate",
    "crumbs": [
      "**DDML模型**",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>交互式模型</span>"
    ]
  },
  {
    "objectID": "body/06_PartiallyLinearModel.html",
    "href": "body/06_PartiallyLinearModel.html",
    "title": "9  部分线性模型",
    "section": "",
    "text": "9.0.0.1 准备工作\n我们加载数据，定义全局宏并设置随机种子。\n. use https://github.com/aahrens1/ddml/raw/master/data/sipp1991.dta, clear\n. global Y net_tfa\n. global D e401\n. global X tw age inc fsize educ db marr twoearn pira hown\n. set seed 42\n\n\n9.0.0.2 步骤 1: 初始化 DDML 模型\n接下来，我们初始化 ddml 估计并选择模型。partial 表示部分线性模型。除非使用 mname(name) 选项指定，否则模型将存储在 Mata 对象中，默认名称为“m0”。\n折数 注意，我们将随机折数设置为 2，以便模型运行得更快。默认值为 kfolds(5)。我们建议考虑至少 5-10 折，如果样本量较小，甚至更多。\nNumber of folds Note that we set the number of random folds to 2, so that the model runs quickly. The default is kfolds(5). We recommend to consider at least 5-10 folds and even more if your sample size is small.\n. ddml init partial, kfolds(2)\n\n\n9.0.0.3 步骤 2: 添加机器学习器\n我们为估计条件期望 \\(E[Y|X]\\) 添加一个监督学习器。首先，我们添加简单的线性回归。\n. ddml E[Y|X]: reg $Y $X\nLearner Y1_reg added successfully.\n我们可以为每个简化方程添加多个学习器。在这里，我们还使用 pystacked 中实现的随机森林学习器。（在下一个示例中，我们展示如何使用 pystacked 堆叠多个学习器，但这里我们只使用它实现一个学习器。）\n. ddml E[Y|X]: pystacked $Y $X, type(reg) method(rf)\nLearner Y2_pystacked added successfully.\n我们对条件期望 \\(E[D|X]\\) 进行同样的操作。\n. ddml E[D|X]: reg $D $X\nLearner D1_reg added successfully.\n. ddml E[D|X]: pystacked $D $X, type(reg) method(rf)\nLearner D2_pystacked added successfully.\n你可以选择检查学习器是否已正确添加。\n. ddml desc\n\n. ddml desc\n\nModel:                  partial, crossfit folds k=2, resamples r=1\nDependent variable (Y): net_tfa\n net_tfa learners:      Y1_reg Y2_pystacked\nD equations (1):        e401\n e401 learners:         D1_reg D2_pystacked\n\n\n9.0.0.4 步骤 3: 交叉拟合\n学习器会在训练数据上进行迭代拟合。此步骤可能需要一些时间。\n. ddml crossfit\nCross-fitting E[Y|X] equation: net_tfa\nCross-fitting fold 1 2 ...completed cross-fitting\nCross-fitting E[D|X] equation: e401\nCross-fitting fold 1 2 ...completed cross-fitting\n\n\n9.0.0.5 步骤 4: 估计\n最后，我们获得感兴趣系数的估计值。由于我们为两个简化方程添加了两个学习器，因此有四种可能的规格。默认情况下，显示的结果对应于具有最低样本外均方误差（MSPE）的规格：\n. ddml estimate, robust\n\n. ddml estimate, robust\n\nDDML estimation results:\nspec  r     Y learner     D learner         b        SE\n   1  1        Y1_reg        D1_reg  5397.308(1130.901)\n   2  1        Y1_reg  D2_pystacked  6707.514 (880.374)\n*  3  1  Y2_pystacked        D1_reg  7044.822(1127.173)\n   4  1  Y2_pystacked  D2_pystacked  6991.835 (755.805)\n* = minimum MSE specification for that resample.\n\nMin MSE DDML model, specification 3\ny-E[y|X]  = Y2_pystacked_1                         Number of obs   =      9915\nD-E[D|X,Z]= D1_reg_1\n------------------------------------------------------------------------------\n             |               Robust\n     net_tfa | Coefficient  std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n        e401 |   7044.822   1127.173     6.25   0.000     4835.603    9254.042\n------------------------------------------------------------------------------\n要估计所有四种规格，我们使用 allcombos 选项：\n. ddml estimate, robust allcombos\n\n. ddml estimate, robust allcombos\n\nDDML estimation results:\nspec  r     Y learner     D learner         b        SE\n   1  1        Y1_reg        D1_reg  5397.208(1130.776)\n   2  1        Y1_reg  D2_pystacked  6705.740 (878.656)\n*  3  1  Y2_pystacked        D1_reg  7044.518(1126.896)\n   4  1  Y2_pystacked  D2_pystacked  6979.699 (753.471)\n* = minimum MSE specification for that resample.\n\nMin MSE DDML model\ny-E[y|X]  = Y2_pystacked_1                         Number of obs   =      9915\nD-E[D|X,Z]= D1_reg_1\n------------------------------------------------------------------------------\n             |               Robust\n     net_tfa | Coefficient  std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n        e401 |   7044.518   1126.896     6.25   0.000     4835.843    9253.193\n       _cons |  -317.8379   352.8666    -0.90   0.368    -1009.444     373.768\n------------------------------------------------------------------------------\n估计所有规格后，我们可以检索特定结果。在这里，我们使用依赖 OLS 估计 \\(E[Y|X]\\) 和 \\(E[D|X]\\) 的规格：\n. ddml estimate, robust spec(1) replay\n\n. ddml estimate, robust spec(1) replay\n\nDDML estimation results:\nspec  r     Y learner     D learner         b        SE\n opt  1  Y2_pystacked        D1_reg  7044.518(1126.896)\nopt = minimum MSE specification for that resample.\n\nDDML model, specification 1\ny-E[y|X]  = Y1_reg_1                               Number of obs   =      9915\nD-E[D|X,Z]= D1_reg_1\n------------------------------------------------------------------------------\n             |               Robust\n     net_tfa | Coefficient  std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n        e401 |   5397.208   1130.776     4.77   0.000     3180.928    7613.488\n       _cons |   -104.854   397.9023    -0.26   0.792     -884.728    675.0201\n------------------------------------------------------------------------------\n\n\n9.0.0.6 常数项的包含\n由于残差化后的结果和处理可能在有限样本中不完全为零，ddml 默认在部分线性模型的估计阶段包含常数项。从渐进角度来看，截距是非必须的。早期版本的 ddml（1.2 之前）未包含常数项。\n你可以通过输入以下命令手动获取相同的点估计：\n. reg Y1_reg D1_reg, robust\n\n. reg Y1_reg D1_reg, robust\n\nLinear regression                               Number of obs     =      9,915\n                                                F(1, 9914)        =      22.78\n                                                Prob &gt; F          =     0.0000\n                                                R-squared         =     0.0037\n                                                Root MSE          =      39626\n\n------------------------------------------------------------------------------\n             |               Robust\n    Y1_reg_1 | Coefficient  std. err.      t    P&gt;|t|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n    D1_reg_1 |   5397.308   1130.901     4.77   0.000     3180.512    7614.105\n------------------------------------------------------------------------------\n或者通过图形展示：\n. twoway (scatter Y1_reg D1_reg) (lfit Y1_reg D1_reg)\n其中，Y1_reg 和 D1_reg 是 net_tfa 和 `e401` 的正交化版本。\n要详细描述 ddml 模型设置或结果，可以使用 ddml describe 并附上相关选项（例如 sample、learners、crossfit、estimates），或者使用 all 选项一次性描述所有内容：\n. ddml describe, all",
    "crumbs": [
      "**DDML模型**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>部分线性模型</span>"
    ]
  },
  {
    "objectID": "body/07_FlexiblePartiallyLinearIVModel.html",
    "href": "body/07_FlexiblePartiallyLinearIVModel.html",
    "title": "10  灵活的部分线性工具变量（IV）模型",
    "section": "",
    "text": "10.0.0.1 准备工作\n我们加载数据、定义全局宏并设置种子。\n. use https://statalasso.github.io/dta/BLP_CHS.dta, clear\n. global Y y\n. global D price\n. global X hpwt air mpd space\n. global Z Zbase*\n. set seed 42\n\n\n10.0.0.2 步骤 1: 初始化\n我们初始化模型。\n. ddml init ivhd\n\n\n10.0.0.3 步骤 2: 添加学习器\n我们按照通常的方式添加学习器以估计 \\(E[Y \\mid X]\\)。\n. ddml E[Y|X]: reg $Y $X\nLearner Y1_reg added successfully.\n\n. ddml E[Y|X]: pystacked $Y $X, type(reg)\nLearner Y2_pystacked added successfully.\n在添加学习器以估计 \\(E[D \\mid Z, X]\\) 和 \\(E[D \\mid X]\\) 时，我们需要注意一些特殊事项。具体来说，估计 \\(E[D \\mid X]\\) 依赖于估计 \\(E[D \\mid X, Z]\\)。更具体地说，我们首先得到拟合值 \\(\\hat{D} = E[D \\mid X, Z]\\)，然后用这些值与 \\(X\\) 进行拟合，来估计 \\(E[\\hat{D} \\mid X]\\)。\n在添加学习器以估计 \\(E[D \\mid Z, X]\\) 时，我们需要为每个学习器提供名称（例如 learner(name)）。\n. ddml E[D|Z,X], learner(Dhat_reg): reg $D $X $Z\nLearner Dhat_reg added successfully.\n\n. ddml E[D|Z,X], learner(Dhat_pystacked): pystacked $D $X $Z, type(reg)\nLearner Dhat_pystacked added successfully.\n在添加学习器以估计 \\(E[D \\mid X]\\) 时，我们明确引用上一阶段的学习器（例如，learner(Dhat_reg)），并提供处理变量的名称（vname($D)）。最后，我们用占位符 {D} 来代替因变量。\n. ddml E[D|X], learner(Dhat_reg) vname($D): reg {D} $X\nLearner Dhat_reg_h added successfully.\n\n. ddml E[D|X], learner(Dhat_pystacked) vname($D): pystacked {D} $X, type(reg)\nReplacing existing learner Dhat_pystacked_h...\nLearner Dhat_pystacked_h added successfully.\n\n\n10.0.0.4 步骤 3-4: 交叉拟合与估计\n现在，我们可以进行交叉拟合和估计。\n. ddml crossfit\nCross-fitting E[Y|X,Z] equation: y\nCross-fitting fold 1 2 3 4 5 ...completed cross-fitting\nCross-fitting E[D|X,Z] and E[D|X] equation: price\nCross-fitting fold 1 2 3 4 5 ...completed cross-fitting\n. ddml estimate, robust\nDDML 估计结果：\nspec  r     Y learner     D learner         b        SE    DH learner\n opt  1  Y2_pystacked Dhat_pystac~d    -0.098  ( 0.008) Dhat_pystac~h\nopt = minimum MSE specification for that resample.\n\nMin MSE DDML model\ny-E[y|X]  = Y2_pystacked_1                         Number of obs   =      2217\nE[D|X,Z]  = Dhat_pystacked_1\nE[D|X]    = Dhat_pystacked_h_1\nOrthogonalised D = D - E[D|X]; optimal IV = E[D|X,Z] - E[D|X].\n------------------------------------------------------------------------------\n             |               Robust\n       share | Coefficient  std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n       price |  -.0979042   .0075006   -13.05   0.000     -.112605   -.0832033\n       _cons |   .0033532   .0215627     0.16   0.876    -.0389089    .0456154\n------------------------------------------------------------------------------\n\n\n10.0.0.5 手动估计\n如果您想知道 ddml 在后台执行了什么，可以使用以下命令：\n. ddml estimate, allcombos spec(8) rep(1) robust\nDDML 估计结果：\nspec  r     Y learner     D learner         b        SE    DH learner\n   1  1        Y1_reg      Dhat_reg    -0.137  ( 0.012)    Dhat_reg_h\n   2  1        Y1_reg      Dhat_reg     0.369  ( 0.207) Dhat_pystac~h\n   3  1        Y1_reg Dhat_pystac~d    -0.089  ( 0.005)    Dhat_reg_h\n   4  1        Y1_reg Dhat_pystac~d    -0.114  ( 0.009) Dhat_pystac~h\n   5  1  Y2_pystacked      Dhat_reg    -0.096  ( 0.011)    Dhat_reg_h\n   6  1  Y2_pystacked      Dhat_reg    -0.212  ( 0.087) Dhat_pystac~h\n   7  1  Y2_pystacked Dhat_pystac~d    -0.042  ( 0.004)    Dhat_reg_h\n*  8  1  Y2_pystacked Dhat_pystac~d    -0.098  ( 0.008) Dhat_pystac~h\n* = minimum MSE specification for that resample.\n\nMin MSE DDML model, specification 8\ny-E[y|X]  = Y2_pystacked_1                         Number of obs   =      2217\nE[D|X,Z]  = Dhat_pystacked_1\nE[D|X]    = Dhat_pystacked_h_1\nOrthogonalised D = D - E[D|X]; optimal IV = E[D|X,Z] - E[D|X].\n------------------------------------------------------------------------------\n             |               Robust\n       share | Coefficient  std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n       price |  -.0979042   .0075006   -13.05   0.000     -.112605   -.0832033\n       _cons |   .0033532   .0215627     0.16   0.876    -.0389089    .0456154\n------------------------------------------------------------------------------\n\n\n10.0.0.6 生成中介变量与工具变量\n. gen Dtilde = $D - Dhat_pystacked_h_1\n. gen Zopt = Dhat_pystacked_1 - Dhat_pystacked_h_1\n\n\n10.0.0.7 工具变量回归\n. ivreg Y2_pystacked_1 (Dtilde=Zopt), robust\n工具变量 2SLS 回归\nInstrumental variables 2SLS regression          Number of obs     =      2,217\n                                                F(1, 2215)        =     170.38\n                                                Prob &gt; F          =     0.0000\n                                                R-squared         =     0.1175\n                                                Root MSE          =     1.0152\n\n------------------------------------------------------------------------------\n             |               Robust\nY2_pystack~1 | Coefficient  std. err.      t    P&gt;|t|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n      Dtilde |  -.0979042   .0075006   -13.05   0.000    -.1126131   -.0831953\n       _cons |   .0033532   .0215627     0.16   0.876     -.038932    .0456385\n------------------------------------------------------------------------------\nInstrumented: Dtilde\n Instruments: Zopt",
    "crumbs": [
      "**DDML模型**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>灵活的部分线性工具变量（IV）模型</span>"
    ]
  },
  {
    "objectID": "body/08_InteractiveIVModel.html",
    "href": "body/08_InteractiveIVModel.html",
    "title": "11  交互式工具变量（IV）模型",
    "section": "",
    "text": "11.0.0.1 准备工作\n我们加载数据，定义全局宏并设置种子。\n. use http://fmwww.bc.edu/repec/bocode/j/jtpa.dta,clear\n. global Y earnings\n. global D training\n. global Z assignmt\n. global X sex age married black hispanic\n. set seed 42\n\n\n11.0.0.2 步骤 1: 初始化\n我们初始化模型。\n. ddml init interactiveiv, kfolds(5)\n\n\n11.0.0.3 步骤 2: 添加学习器\n我们使用堆叠（在 pystacked 中实现）并为每个简化方程添加两个基础学习器。\n. ddml E[Y|X,Z]: pystacked $Y c.($X)# #c($X), type(reg) m(ols lassocv)\nLearner Y1_pystacked added successfully.\n\n. ddml E[D|X,Z]: pystacked $D c.($X)# #c($X), type(class) m(logit lassocv)\nLearner D1_pystacked added successfully.\n\n. ddml E[Z|X]: pystacked $Z c.($X)# #c($X), type(class) m(logit lassocv)\nLearner Z1_pystacked added successfully.\n\n\n11.0.0.4 步骤 3-4: 交叉拟合与估计\n. ddml crossfit\nCross-fitting E[y|X,Z] equation: earnings\nCross-fitting fold 1 2 3 4 5 ...completed cross-fitting\nCross-fitting E[D|X,Z] equation: training\nCross-fitting fold 1 2 3 4 5 ...completed cross-fitting\nCross-fitting E[Z|X]: assignmt\nCross-fitting fold 1 2 3 4 5 ...completed cross-fitting\n\n. ddml estimate\nDDML 估计结果 (LATE)：\nspec  r    Y0 learner    Y1 learner    D0 learner    D1 learner         b        SE     Z learner\n opt  1  Y1_pystacked  Y1_pystacked  D1_pystacked  D1_pystacked  1817.206 (512.772)  Z1_pystacked\nopt = minimum MSE specification for that resample.\n\nE[y|X,D=0]   = Y1_pystacked0_1                     Number of obs   =     11204\nE[y|X,D=1]   = Y1_pystacked1_1\nE[D|X,Z=0]   = D1_pystacked0_1\nE[D|X,Z=1]   = D1_pystacked1_1\nE[Z|X]       = Z1_pystacked_1\n------------------------------------------------------------------------------\n             |               Robust\n    earnings | Coefficient  std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n    training |   1817.206   512.7723     3.54   0.000     812.1911    2822.221\n------------------------------------------------------------------------------\n\n\n11.0.0.5 短堆叠（Short-stacking）\n如果我们想要使用短堆叠而不是堆叠，步骤如下：\n初始化：\n. set seed 42\n. ddml init interactiveiv, kfolds(5)\nwarning - model m0 already exists\nall existing model results and variables will\nbe dropped and model m0 will be re-initialized\n添加基础学习器：\n. ddml E[Y|X,Z]: reg $Y $X\nLearner Y1_reg added successfully.\n. ddml E[Y|X,Z]: pystacked $Y c.($X)# #c($X), type(reg) m(lassocv)\nLearner Y2_pystacked added successfully.\n. ddml E[D|X,Z]: logit $D $X\nLearner D1_logit added successfully.\n. ddml E[D|X,Z]: pystacked $D c.($X)# #c($X), type(class) m(lassocv)\nLearner D2_pystacked added successfully.\n. ddml E[Z|X]: logit $Z $X\nLearner Z1_logit added successfully.\n. ddml E[Z|X]: pystacked $Z c.($X)# #c($X), type(class) m(lassocv)\nLearner Z2_pystacked added successfully.\n使用短堆叠选项进行交叉拟合：\n. ddml crossfit, shortstack\nCross-fitting E[y|X,Z] equation: earnings\nCross-fitting fold 1 2 3 4 5 ...completed cross-fitting...completed short-stacking\nCross-fitting E[D|X,Z] equation: training\nCross-fitting fold 1 2 3 4 5 ...completed cross-fitting...completed short-stacking\nCross-fitting E[Z|X]: assignmt\nCross-fitting fold 1 2 3 4 5 ...completed cross-fitting...completed short-stacking\n估计阶段：\n. ddml estimate, robust\n短堆叠 DDML 模型 (LATE)：\nspec  r    Y0 learner    Y1 learner    D0 learner    D1 learner         b        SE     Z learner\n opt  1  Y2_pystacked  Y2_pystacked      D1_logit  D2_pystacked  1824.422 (514.303)  Z2_pystacked\n  ss  1  [shortstack]          [ss]          [ss]          [ss]  1818.488 (513.133)          [ss]\nopt = minimum MSE specification for that resample.\n\nShortstack DDML model (LATE)\nE[y|X,D=0]   = earnings_ss0_1                      Number of obs   =     11204\nE[y|X,D=1]   = earnings_ss1_1\nE[D|X,Z=0]   = training_ss0_1\nE[D|X,Z=1]   = training_ss1_1\nE[Z|X]       = assignmt_ss_1\n------------------------------------------------------------------------------\n             |               Robust\n    earnings | Coefficient  std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n    training |   1818.488    513.133     3.54   0.000     812.7663    2824.211\n------------------------------------------------------------------------------",
    "crumbs": [
      "**DDML模型**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>交互式工具变量（IV）模型</span>"
    ]
  },
  {
    "objectID": "body/09_Installation.html",
    "href": "body/09_Installation.html",
    "title": "12  安装 ddml",
    "section": "",
    "text": "12.0.0.1 从 SSC 安装\n您可以通过 SSC 安装 ddml：\nssc install ddml, replace\n\n\n12.0.0.2 从 Github 安装\n我们建议使用 Github 上更新更频繁的版本，您可以通过以下命令安装最新版：\nnet install ddml, /// \n    from(https://raw.githubusercontent.com/aahrens1/ddml/master) /// \n    replace\n如果您想安装旧版本，可以使用以下命令（例如安装 v1.2 版本）：\nnet install ddml, /// \n    from(https://raw.githubusercontent.com/aahrens1/ddml/v1.2) /// \n    replace\n请定期检查更新。\n\n\n12.0.1 离线安装\n如果您想在没有网络连接的环境下使用 ddml，建议您从 Github 下载包文件。点击绿色的 “Code” 按钮，然后选择 “Download ZIP”。下载并解压后，使用以下命令进行离线安装，确保 from() 指向您下载并解压后的仓库文件夹：\nnet install ddml, /// \n    from(path_to_unzipped_repository) /// \n    replace",
    "crumbs": [
      "**DDML模型**",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>安装 ddml</span>"
    ]
  },
  {
    "objectID": "body/11_Readingspaper.html",
    "href": "body/11_Readingspaper.html",
    "title": "13  ddml",
    "section": "",
    "text": "Ahrens, A., Hansen, C.B., Schaffer, M.E., and Wiemann, T. (2023). ddml: Double/Debiased Machine Learning in Stata. arXiv preprint arXiv:2301.09397.\n我们介绍了 Stata 中的 ddml 包，用于双重/去偏机器学习（Double/Debiased Machine Learning，简称 DDML）。该包支持五种不同计量经济学模型的因果参数估计，能够灵活估计内生变量在功能形式未知和/或外生变量众多的情况下的因果效应。ddml 与 Stata 中许多现有的监督学习程序兼容。我们推荐将 DDML 与堆叠估计（stacking estimation）结合使用，堆叠估计将多个机器学习模型结合成最终的预测器。我们提供了蒙特卡洛证据来支持我们的推荐。\n链接到工作论文\nBibtex 文件\n\n\n13.0.1 pystacked\nAhrens, A., Hansen, C.B., and Schaffer, M.E. (2022). pystacked: Stacking Generalization and Machine Learning in Stata. arXiv preprint arXiv:2208.10896.\npystacked 实现了堆叠泛化（stacked generalization，Wolpert，1992），用于通过 Python 的 scikit-learn 进行回归和二分类。堆叠将多个监督学习模型（“基础”或“第 0 层”模型）组合成一个单一的学习器。当前支持的基础学习器包括正则化回归、随机森林、梯度提升树、支持向量机和前馈神经网络（多层感知机）。pystacked 也可以作为一个常规机器学习程序使用，拟合单个基础学习器，因此为 scikit-learn 的机器学习算法提供了一个易于使用的 API。\n链接到工作论文\nBibtex 文件\n\n\n\n13.0.2 lassopack\nAhrens, A., Hansen, C.B., Schaffer, M.E. (2020). lassopack: Model Selection and Prediction with Regularized Regression in Stata. The Stata Journal, 20(1):176-235. doi:10.1177/1536867X20909697\n在这篇文章中，我们介绍了 lassopack，一个用于 Stata 的正则化回归程序集。lassopack 实现了 Lasso、平方根 Lasso、弹性网、岭回归、自适应 Lasso 和后验普通最小二乘法（OLS）。这些方法适用于高维设置，其中预测变量 \\(p\\) 可能很大，甚至大于观察值的数量 \\(n\\)。我们提供了三种选择惩罚（“调优”）参数的方法：信息准则（在 lasso2 中实现）、K 折交叉验证以及用于横截面、面板和时间序列数据的 h 步前滚动交叉验证（cvlasso），以及理论驱动（“严格”或插件）惩罚方法用于横截面和面板数据的 Lasso 和平方根 Lasso（rlasso）。我们讨论了每种方法的理论框架和实践考虑。我们还提供了蒙特卡洛结果，以比较不同惩罚方法的表现。\n下载早期的 arXiv 版本 - Stata Journal 论文\n如果您在访问 SJ 版本时遇到问题，请随时联系我（AA）。\nBibtex 文件\n\n\n\n13.0.3 幻灯片\n来自我们在 2018 年伦敦 Stata 大会上的演讲幻灯片可在此处查看。 pystacked 的演讲幻灯片可以在这里找到。 ddml 的演讲幻灯片可以在这里找到。",
    "crumbs": [
      "**参考资料**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>ddml</span>"
    ]
  }
]